# -*- coding: utf-8 -*-
"""Trained model accuracy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W2hXa9j21wBL6YRnprvhwAm5sCAU6fis
"""

#import libraries
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report

# Load dataset
file_path = '/content/Data for training (Survey).csv'  # Update this path if needed
df = pd.read_csv(file_path)

# Select relevant columns
columns_to_keep = ["Age", "Gender", "family_history", "work_interfere", "no_employees",
                    "leave", "mental_health_consequence", "phys_health_consequence",
                    "supervisor", "mental_vs_physical", "obs_consequence", "comments", "treatment"]
df = df[columns_to_keep]

# Clean gender column
def clean_gender(gender):
    gender = gender.lower()
    if gender in ['male', 'm']: return 'Male'

# Apply the function to clean gender column
df['Gender'] = df['Gender'].astype(str).apply(clean_gender)

# Fill missing values with "Unknown" where applicable
df.fillna("Unknown", inplace=True)

# Remove rows with missing values in the target variable ('treatment')
df = df.dropna(subset=['treatment'])

# Encode categorical variables
label_cols = ["Gender", "family_history", "work_interfere", "no_employees", "leave",
              "mental_health_consequence", "phys_health_consequence", "supervisor",
              "mental_vs_physical", "obs_consequence"]
encoder = LabelEncoder()
for col in label_cols:
    df[col] = encoder.fit_transform(df[col])

# Convert target variable "treatment" to binary
df['treatment'] = df['treatment'].map({'Yes': 1, 'No': 0})

# Feature and Target Split
X = df.drop(columns=['treatment', 'comments'])
y = df['treatment']

# Standardizing numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training 80% and testing 20%
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)



best_model_name = None  # Store the best model's name
best_accuracy = 0  # Store the highest accuracy found
best_model = None  # Store the actual best model object

# Save only the best-performing model for future use
joblib.dump(best_model, "best_mental_health_model.joblib")

# Save the scaler to preprocess new user input in the backend
joblib.dump(scaler, "mental_health_scaler.joblib")

# Save best model information to a log file for reference
with open("best_model_performance.txt", "w") as f:
    f.write(f"Best Model: {best_model_name}\nAccuracy: {best_accuracy:.2f}\n")

# Print final confirmation
print(f"âœ… Best model ({best_model_name}) saved successfully with accuracy: {best_accuracy:.2f}")

log_reg = LogisticRegression(max_iter=1000, solver='liblinear')

log_reg.fit(X_train, y_train)

# Predict using the loaded model
predictions = log_reg.predict(X_scaled)

# Predict using the loaded model
predictions = log_reg.predict(X_scaled)

# Calculate evaluation metrics
accuracy = accuracy_score(y, predictions)
f1 = f1_score(y, predictions, average='weighted')
precision = precision_score(y, predictions, average='weighted')
recall = recall_score(y, predictions, average='weighted')
conf_matrix = confusion_matrix(y, predictions)
classification_rep = classification_report(y, predictions)

# Display results
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_rep)

knn=KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train, y_train)

# Predict using the loaded model
predictions = knn.predict(X_scaled)

# Predict using the loaded model
predictions = knn.predict(X_scaled)

# Calculate evaluation metrics
accuracy = accuracy_score(y, predictions)
f1 = f1_score(y, predictions, average='weighted')
precision = precision_score(y, predictions, average='weighted')
recall = recall_score(y, predictions, average='weighted')
conf_matrix = confusion_matrix(y, predictions)
classification_rep = classification_report(y, predictions)

# Display results
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_rep)

rf = RandomForestClassifier(n_estimators=100, random_state=42)  # You can tune n_estimators
rf.fit(X_train, y_train)

# Predict using the loaded model
predictions = rf.predict(X_scaled)

# Calculate evaluation metrics
accuracy = accuracy_score(y, predictions)
f1 = f1_score(y, predictions, average='weighted')
precision = precision_score(y, predictions, average='weighted')
recall = recall_score(y, predictions, average='weighted')
conf_matrix = confusion_matrix(y, predictions)
classification_rep = classification_report(y, predictions)

# Display results
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_rep)

